{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using built-in xgboost with AI Platform Training\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use AI Platfrom Training built-in XGBoost algorithm. You will train a multi-class classification model that predicts the type of forest cover from cartographic data. The [dataset](../../../datasets/covertype/README.md) used in the lab is based on **Covertype Data Set** from UCI Machine Learning Repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import uuid\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from jinja2 import Template\n",
    "from kfp.components import func_to_container_op\n",
    "from typing import NamedTuple\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set location paths, connections strings, and other environment settings. Make sure to update   `REGION`, and `ARTIFACT_STORE`  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket used for storing data and output from AI Platform Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ARTIFACT_STORE = 'gs://mlops-dev-workspace/xgboos-demo'\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "DATA_ROOT='{}/data'.format(ARTIFACT_STORE)\n",
    "JOB_DIR_ROOT='{}/jobs'.format(ARTIFACT_STORE)\n",
    "\n",
    "ORIG_DATASET = 'gs://workshop-datasets/covertype/small/dataset.csv'\n",
    "TRAINING_DATASET = '{}/covertype_preprocessed/dataset.csv'.format(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset for the built-in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert numeric features to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_indexes = slice(0, 10)\n",
    "num_features_type_map = {feature: 'float64' for feature in df.columns[numeric_feature_indexes]}\n",
    "\n",
    "df_training = df.astype(num_features_type_map)\n",
    "df_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move the target column  to the first position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)\n",
    "columns.insert(0, columns.pop(columns.index('Cover_Type')))\n",
    "\n",
    "df_training = df_training.reindex(columns=columns)\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv(TRAINING_DATASET, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat -r 0-297 {TRAINING_DATASET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URI = 'gcr.io/cloud-ml-algos/boosted_trees:latest'\n",
    "\n",
    "JOB_NAME = 'job_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "JOB_DIR = '{}/{}'.format(JOB_DIR_ROOT, JOB_NAME)\n",
    "SCALE_TIER = 'CUSTOM'\n",
    "MASTER_TYPE = 'n1-standard-16'\n",
    "\n",
    "VALIDATION_SPLIT = 0.10\n",
    "TEST_SPLIT = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs submit training {JOB_NAME} \\\n",
    "--master-image-uri={IMAGE_URI} \\\n",
    "--scale-tier={SCALE_TIER} \\\n",
    "--master-machine-type={MASTER_TYPE} \\\n",
    "--job-dir={JOB_DIR} \\\n",
    "--region={REGION} \\\n",
    "-- \\\n",
    "--preprocess \\\n",
    "--objective=multi:softmax \\\n",
    "--training_data_path={TRAINING_DATASET} \\\n",
    "--validation_split={VALIDATION_SPLIT} \\\n",
    "--test_split={TEST_SPLIT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs stream-logs $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the job's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls {JOB_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat {JOB_DIR}/artifacts/instance_generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and submit the hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the hyperparameter configuration file. \n",
    "\n",
    "\n",
    "The below file configures AI Platform hypertuning to run up to 12 trials on up to three nodes and to choose from three discrete values of `max_depth` and the linear range betwee 0.2 and 0.4 for `eta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPTUNING_CONFIG = 'hptuning_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {HPTUNING_CONFIG}\n",
    "\n",
    "# Copyright 2019 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 12\n",
    "    maxParallelTrials: 3\n",
    "    hyperparameterMetricTag: merror\n",
    "    enableTrialEarlyStopping: TRUE \n",
    "    params:\n",
    "    - parameterName: max_depth\n",
    "      type: DISCRETE\n",
    "      discreteValues: [\n",
    "          8,\n",
    "          10,\n",
    "          12\n",
    "          ]\n",
    "    - parameterName: eta\n",
    "      type: DOUBLE\n",
    "      minValue:  0.2\n",
    "      maxValue:  0.4\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the hyperparameter tuning job.\n",
    "\n",
    "Use the `gcloud` command to start the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = 'job_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "JOB_DIR = '{}/{}'.format(JOB_DIR_ROOT, JOB_NAME)\n",
    "SCALE_TIER = 'CUSTOM'\n",
    "MASTER_TYPE = 'n1-standard-16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs submit training {JOB_NAME} \\\n",
    "--master-image-uri={IMAGE_URI} \\\n",
    "--scale-tier={SCALE_TIER} \\\n",
    "--master-machine-type={MASTER_TYPE} \\\n",
    "--job-dir={JOB_DIR} \\\n",
    "--region={REGION} \\\n",
    "--config {HPTUNING_CONFIG} \\\n",
    "-- \\\n",
    "--preprocess \\\n",
    "--objective=multi:softmax \\\n",
    "--training_data_path={TRAINING_DATASET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs stream-logs $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve HP-tuning results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the job completes you can review the results using GCP Console or programatically by calling the AI Platform Training REST end-point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = discovery.build('ml', 'v1')\n",
    "\n",
    "job_id = 'projects/{}/jobs/{}'.format(PROJECT_ID, JOB_NAME)\n",
    "request = ml.projects().jobs().get(name=job_id)\n",
    "\n",
    "try:\n",
    "    response = request.execute()\n",
    "except errors.HttpError as err:\n",
    "    print(err)\n",
    "except:\n",
    "    print(\"Unexpected error\")\n",
    "    \n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned run results are sorted by a value of the optimization metric. The best run is the first item on the returned list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['trainingOutput']['trials'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to AI Platform Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the deployment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output = response['trainingOutput']['trials'][0]['builtInAlgorithmOutput']['modelPath']\n",
    "\n",
    "!gsutil cp  {training_output}/deployment_config.yaml .\n",
    "!cat deployment_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'covertype'\n",
    "ALGORITHM = 'xgboost'\n",
    "MODEL_TYPE = 'classification'\n",
    "MODEL_NAME = '{}_{}_{}'.format(DATASET_NAME, ALGORITHM, MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform models create  $MODEL_NAME \\\n",
    "    --regions={REGION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 'v1'\n",
    "\n",
    "!gcloud ai-platform versions create {MODEL_VERSION} \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --config deployment_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve predictions\n",
    "#### Download training artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_artifacts = training_output[:-14]\n",
    "#training_artifacts\n",
    "!gsutil ls {training_artifacts}/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp {training_artifacts}/artifacts/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the input file with JSON formated instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_FILE = 'serving_instance.json'\n",
    "RAW_DATA_POINT = '3142.0, 183.0, 9.0, 648.0, 101.0, 757.0, 223.0, 247.0, 157.0, 1871.0, Commanche, C7757'\n",
    "\n",
    "!python instance_generator.py --raw_data_string=\"{RAW_DATA_POINT}\" > {INSTANCE_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {INSTANCE_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform predict \\\n",
    "--model {MODEL_NAME} \\\n",
    "--version {MODEL_VERSION} \\\n",
    "--json-instances {INSTANCE_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
